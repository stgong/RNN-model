{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.fit() fine tune the RNN hidden layer parameter\n",
    "#### layers = [200, 250, 300,'200-100','300-200','200-100-50', '300-200-100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(1000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 1 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "!python -V\n",
    "!git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-12 19:45:34.142194: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-12 19:45:34.474755: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895480000 Hz\n",
      "2019-12-12 19:45:34.475774: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x52655f0 executing computations on platform Host. Devices:\n",
      "2019-12-12 19:45:34.475822: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-12 19:45:49.926437: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7410_8009' and '__inference___backward_standard_lstm_7410_8009_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8146' both implement 'lstm_ef0c66b6-8401-4f04-abeb-13d02c4a7d3e' but their signatures do not match.\n",
      "2019-12-12 19:45:53.272353: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.375420). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.122670). Check your callbacks.\n",
      "2019-12-12 19:49:52.830400: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19815' and '__inference_standard_lstm_19472_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21340' both implement 'lstm_4790ceda-558a-4753-96b2-35cac65c5733' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.89269, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 249s - loss: 6.9481 - val_loss: 6.8927\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.89269 to 6.84715, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.8792 - val_loss: 6.8472\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.84715 to 6.80179, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 247s - loss: 6.8142 - val_loss: 6.8018\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.80179 to 6.75154, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 254s - loss: 6.7803 - val_loss: 6.7515\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.75154\n",
      "177316/177316 - 249s - loss: 6.7336 - val_loss: 6.7557\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.75154 to 6.71344, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 249s - loss: 6.6774 - val_loss: 6.7134\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.71344 to 6.65282, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 250s - loss: 6.6374 - val_loss: 6.6528\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.65282 to 6.61956, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 249s - loss: 6.6015 - val_loss: 6.6196\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.61956 to 6.59987, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 252s - loss: 6.5606 - val_loss: 6.5999\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.59987\n",
      "177316/177316 - 251s - loss: 6.5231 - val_loss: 6.6041\n",
      "[6.94811860379506, 6.879202375879046, 6.814226186365032, 6.78034038051471, 6.73357450857457, 6.677416436217038, 6.637433948715631, 6.6015215811458035, 6.560601436996899, 6.523124260616167]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  2498.0048644542694  epochs in 2552.22132730484 s\n",
      "Last train cost :  6.7155559718819955\n",
      "recall :  0.04926736139584846\n",
      "precision :  0.08028616852146298\n",
      "sps :  0.05087440381558029\n",
      "Best  sps :  0.05087440381558029\n",
      "sps_short :  0.046052631578947366\n",
      "sps_long :  0.055384615384615386\n",
      "user_coverage :  0.534181240063593\n",
      "item_coverage :  115\n",
      "total_item_coverage :  505\n",
      "uniq_rec :  249\n",
      "ndcg :  0.08527619516459846\n",
      "blockbuster_share :  0.45544554455445546\n",
      "intra_list_similarity :  7.485150522473445\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2498.005_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 10 --r_l 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-12 20:30:16.502398: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-12 20:30:16.526705: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895480000 Hz\n",
      "2019-12-12 20:30:16.527072: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x414fde0 executing computations on platform Host. Devices:\n",
      "2019-12-12 20:30:16.527106: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "['ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2498.005_gc100_e100_h100_Ug_lr0.1_nt1.hdf5']\n",
      "Opening file (1)\n",
      "Timer:  53.171163331\n",
      "-------------------\n",
      "( 1 / 1 ) results on ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2498.005_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "sps@10:  0.07631160572337042\n",
      "sps_short@10:  0.06774193548387097\n",
      "sps_long@10:  0.08463949843260188\n",
      "recall@10:  0.052245336584076915\n",
      "precision@10:  0.09236883942766332\n",
      "uniq_rec@10:  287\n",
      "total_item_coverage@10:  581\n",
      "item_coverage@10:  144\n",
      "user_coverage@10:  0.5500794912559619\n",
      "ndcg@10:  0.0981475700676602\n",
      "blockbuster_share@10:  0.40963855421686746\n",
      "intra_list_similarity@10:  7.241215887277673\n"
     ]
    }
   ],
   "source": [
    "!python test.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --r_l 100 -i 2498.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-12 20:36:15.960697: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-12 20:36:15.982705: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895480000 Hz\n",
      "2019-12-12 20:36:15.982972: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x40f2cc0 executing computations on platform Host. Devices:\n",
      "2019-12-12 20:36:15.982997: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/20\n",
      "2019-12-12 20:36:23.977181: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7410_8009' and '__inference___backward_standard_lstm_7410_8009_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8146' both implement 'lstm_8a956a3a-2aa4-4b44-9dec-4f22c3958278' but their signatures do not match.\n",
      "2019-12-12 20:36:24.422067: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.328388). Check your callbacks.\n",
      "2019-12-12 20:40:22.207801: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19815' and '__inference_standard_lstm_19472_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21340' both implement 'lstm_0df19514-f882-4be9-aa12-91bed14ae6ae' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.89269, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 242s - loss: 6.9481 - val_loss: 6.8927\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.89269 to 6.84715, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 247s - loss: 6.8792 - val_loss: 6.8472\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.84715 to 6.80179, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.8142 - val_loss: 6.8018\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.80179 to 6.75154, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 245s - loss: 6.7803 - val_loss: 6.7515\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.75154\n",
      "177316/177316 - 246s - loss: 6.7336 - val_loss: 6.7557\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.75154 to 6.71344, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 244s - loss: 6.6774 - val_loss: 6.7134\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.71344 to 6.65282, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.6374 - val_loss: 6.6528\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.65282 to 6.61956, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 244s - loss: 6.6015 - val_loss: 6.6196\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.61956 to 6.59987, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.5606 - val_loss: 6.5999\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.59987\n",
      "177316/177316 - 244s - loss: 6.5231 - val_loss: 6.6041\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 00011: val_loss improved from 6.59987 to 6.58941, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 245s - loss: 6.4866 - val_loss: 6.5894\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 00012: val_loss improved from 6.58941 to 6.53589, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 245s - loss: 6.4484 - val_loss: 6.5359\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 00013: val_loss improved from 6.53589 to 6.52278, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 245s - loss: 6.4152 - val_loss: 6.5228\n",
      "Epoch 14/20\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 6.52278\n",
      "177316/177316 - 245s - loss: 6.3863 - val_loss: 6.5365\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 6.52278\n",
      "177316/177316 - 244s - loss: 6.3583 - val_loss: 6.5455\n",
      "Epoch 16/20\n",
      "\n",
      "Epoch 00016: val_loss improved from 6.52278 to 6.51651, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 245s - loss: 6.3304 - val_loss: 6.5165\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 6.51651\n",
      "177316/177316 - 244s - loss: 6.3044 - val_loss: 6.5349\n",
      "Epoch 18/20\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 6.51651\n",
      "177316/177316 - 245s - loss: 6.2798 - val_loss: 6.5217\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 00019: val_loss improved from 6.51651 to 6.51573, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 247s - loss: 6.2567 - val_loss: 6.5157\n",
      "Epoch 20/20\n",
      "\n",
      "Epoch 00020: val_loss improved from 6.51573 to 6.51077, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.2328 - val_loss: 6.5108\n",
      "[6.94811860379506, 6.879202375879046, 6.814226186365032, 6.78034038051471, 6.73357450857457, 6.677416436217038, 6.637433948715631, 6.6015215811458035, 6.560601436996899, 6.523124260616167, 6.486643334014204, 6.448387707736491, 6.41520447976165, 6.386331007566622, 6.3582913070704015, 6.330447896064886, 6.3043580901257315, 6.279755824810895, 6.2566592434574595, 6.232819713399854]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  4903.255256414413  epochs in 4956.018971204758 s\n",
      "Last train cost :  6.532722916141408\n",
      "recall :  0.05450064628948946\n",
      "precision :  0.08934817170111328\n",
      "sps :  0.07313195548489666\n",
      "Best  sps :  0.07313195548489666\n",
      "sps_short :  0.06907894736842106\n",
      "sps_long :  0.07692307692307693\n",
      "user_coverage :  0.5453100158982512\n",
      "item_coverage :  191\n",
      "total_item_coverage :  562\n",
      "uniq_rec :  581\n",
      "ndcg :  0.0928241509880779\n",
      "blockbuster_share :  0.37544483985765126\n",
      "intra_list_similarity :  6.760951503581973\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4903.255_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 20 --r_l 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-12 22:02:35.470138: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-12 22:02:35.494672: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895480000 Hz\n",
      "2019-12-12 22:02:35.494991: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x42a8ee0 executing computations on platform Host. Devices:\n",
      "2019-12-12 22:02:35.495022: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "['ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4903.255_gc100_e100_h100_Ug_lr0.1_nt1.hdf5']\n",
      "Opening file (1)\n",
      "Timer:  54.115255055\n",
      "-------------------\n",
      "( 1 / 1 ) results on ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4903.255_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "sps@10:  0.08267090620031796\n",
      "sps_short@10:  0.06774193548387097\n",
      "sps_long@10:  0.09717868338557993\n",
      "recall@10:  0.05231770021490292\n",
      "precision@10:  0.09220985691573963\n",
      "uniq_rec@10:  633\n",
      "total_item_coverage@10:  580\n",
      "item_coverage@10:  224\n",
      "user_coverage@10:  0.5453100158982512\n",
      "ndcg@10:  0.09702003211070638\n",
      "blockbuster_share@10:  0.3603448275862069\n",
      "intra_list_similarity@10:  6.463133680289377\n"
     ]
    }
   ],
   "source": [
    "!python test.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --r_l 100 -i 4903.255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 4, done.\u001b[K\n",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 4 (delta 0), reused 2 (delta 0), pack-reused 0\u001b[K\n",
      "Entpacke Objekte: 100% (4/4), Fertig.\n",
      "Von https://github.com/stgong/RNN-model\n",
      " * branch            tf2.0_tensorboard -> FETCH_HEAD\n",
      "   52be3bd..2487d63  tf2.0_tensorboard -> origin/tf2.0_tensorboard\n",
      "Aktualisiere 52be3bd..2487d63\n",
      "Fast-forward\n",
      " ...s_tensorboard run on tf.v1_all-checkpoint.ipynb | 369 \u001b[32m+++++++++++++++++++++\u001b[m\n",
      " TestingResuts_tensorboard run on tf.v1_all.ipynb   | 190 \u001b[32m+++++++++++\u001b[m\n",
      " 2 files changed, 559 insertions(+)\n",
      " create mode 100644 .ipynb_checkpoints/TestingResuts_tensorboard run on tf.v1_all-checkpoint.ipynb\n",
      " create mode 100644 TestingResuts_tensorboard run on tf.v1_all.ipynb\n",
      "[tf2.0_tensorboard 5a1ade6] emb100h100 epoch 20 train on remote_PC\n",
      " Committer: nicolakang <nicolakang@mailbox.tu-berlin.de>\n",
      "Ihr Name und E-Mail Adresse wurden automatisch auf Basis\n",
      "Ihres Benutzer- und Rechnernamens konfiguriert. Bitte prüfen Sie, dass\n",
      "diese zutreffend sind. Sie können diese Meldung unterdrücken, indem Sie\n",
      "diese explizit setzen:\n",
      "\n",
      "    git config --global user.name \"Ihr Name\"\n",
      "    git config --global user.email ihre@emailadresse.de\n",
      "\n",
      "Nachdem Sie das getan haben, können Sie Ihre Identität für diesen Commit ändern:\n",
      "\n",
      "    git commit --amend --reset-author\n",
      "\n",
      " 17 files changed, 768 insertions(+), 4 deletions(-)\n",
      " rename .ipynb_checkpoints/{LocalVirtual-HiddenUnit-own_emb-b4tensorborad-checkpoint.ipynb => LocalVirtual-HiddenUnit-own_emb-tf2.0-checkpoint.ipynb} (100%)\n",
      " create mode 100644 .ipynb_checkpoints/RemotePC_HiddenUnit-own_emb-tf2.0-checkpoint.ipynb\n",
      " rename LocalVirtual-HiddenUnit-own_emb-b4tensorborad.ipynb => LocalVirtual-HiddenUnit-own_emb-tf2.0.ipynb (99%)\n",
      " create mode 100644 RemotePC_HiddenUnit-own_emb-tf2.0.ipynb\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2498.005_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4903.255_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 logs/20191212-194534/train/events.out.tfevents.1576176345.tintel206d3.20645.2278.v2\n",
      " create mode 100644 logs/20191212-194534/train/events.out.tfevents.1576176353.tintel206d3.profile-empty\n",
      " create mode 100644 logs/20191212-194534/train/plugins/profile/2019-12-12_19-45-53/local.trace\n",
      " create mode 100644 logs/20191212-194534/validation/events.out.tfevents.1576176594.tintel206d3.20645.21407.v2\n",
      " create mode 100644 logs/20191212-203615/train/events.out.tfevents.1576179380.tintel206d3.21897.2278.v2\n",
      " create mode 100644 logs/20191212-203615/train/events.out.tfevents.1576179385.tintel206d3.profile-empty\n",
      " create mode 100644 logs/20191212-203615/train/plugins/profile/2019-12-12_20-36-25/local.trace\n",
      " create mode 100644 logs/20191212-203615/validation/events.out.tfevents.1576179622.tintel206d3.21897.21407.v2\n",
      "Zähle Objekte: 33, Fertig.\n",
      "Delta compression using up to 4 threads.\n",
      "Komprimiere Objekte: 100% (25/25), Fertig.\n",
      "Schreibe Objekte: 100% (33/33), 9.91 MiB | 4.38 MiB/s, Fertig.\n",
      "Total 33 (delta 9), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (9/9), completed with 5 local objects.\u001b[K\n",
      "To https://github.com/stgong/RNN-model.git\n",
      "   2487d63..5a1ade6  tf2.0_tensorboard -> tf2.0_tensorboard\n",
      "Branch 'tf2.0_tensorboard' folgt nun Remote-Branch 'tf2.0_tensorboard' von 'origin'.\n"
     ]
    }
   ],
   "source": [
    "!git pull origin tf2.0_tensorboard\n",
    "!git add .\n",
    "!git commit -m 'emb100h100 epoch 20 train on remote_PC'\n",
    "!git push -u origin tf2.0_tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-12 22:44:47.304836: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-12 22:44:47.330809: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895480000 Hz\n",
      "2019-12-12 22:44:47.331818: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3e42690 executing computations on platform Host. Devices:\n",
      "2019-12-12 22:44:47.331855: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-12 22:44:55.332637: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7410_8009' and '__inference___backward_standard_lstm_7410_8009_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8146' both implement 'lstm_2e368a41-adf6-4798-9151-04daa5f63772' but their signatures do not match.\n",
      "2019-12-12 22:44:55.757222: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.312249). Check your callbacks.\n",
      "2019-12-12 22:47:26.452868: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19815' and '__inference_standard_lstm_19472_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21340' both implement 'lstm_99426ed0-e65d-4d21-b21c-93289c3cb697' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.89692, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 155s - loss: 6.9508 - val_loss: 6.8969\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.89692 to 6.84524, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 148s - loss: 6.8857 - val_loss: 6.8452\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.84524 to 6.81404, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 143s - loss: 6.8202 - val_loss: 6.8140\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.81404 to 6.79331, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 142s - loss: 6.7894 - val_loss: 6.7933\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.79331 to 6.74029, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 143s - loss: 6.7564 - val_loss: 6.7403\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.74029 to 6.71065, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 142s - loss: 6.6948 - val_loss: 6.7106\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 6.71065\n",
      "177316/177316 - 140s - loss: 6.6466 - val_loss: 6.7236\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.71065 to 6.62134, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 141s - loss: 6.6135 - val_loss: 6.6213\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.62134\n",
      "177316/177316 - 151s - loss: 6.5790 - val_loss: 6.6341\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss improved from 6.62134 to 6.60670, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 151s - loss: 6.5420 - val_loss: 6.6067\n",
      "[6.950835708837258, 6.885747524302695, 6.820190046057813, 6.789365367054248, 6.756405813538188, 6.694841228645513, 6.646594535764215, 6.613526362854756, 6.578951806029674, 6.541955912572235]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  1458.3876721858978  epochs in 1511.2133071422577 s\n",
      "Last train cost :  6.727841430565659\n",
      "recall :  0.04848961437769223\n",
      "precision :  0.0801271860095393\n",
      "sps :  0.057233704292527825\n",
      "Best  sps :  0.057233704292527825\n",
      "sps_short :  0.049342105263157895\n",
      "sps_long :  0.06461538461538462\n",
      "user_coverage :  0.519872813990461\n",
      "item_coverage :  107\n",
      "total_item_coverage :  504\n",
      "uniq_rec :  229\n",
      "ndcg :  0.0860559544684956\n",
      "blockbuster_share :  0.47023809523809523\n",
      "intra_list_similarity :  7.826640214674458\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne1458.388_gc100_e100_h50_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 10 --r_l 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-12 23:10:05.145305: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-12 23:10:05.166701: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895480000 Hz\n",
      "2019-12-12 23:10:05.167067: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x484f070 executing computations on platform Host. Devices:\n",
      "2019-12-12 23:10:05.167092: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-12 23:10:12.977208: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7410_8009' and '__inference___backward_standard_lstm_7410_8009_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8146' both implement 'lstm_d80d3c06-87fe-4d71-8b82-c9ce8a708c71' but their signatures do not match.\n",
      "2019-12-12 23:10:13.439509: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.309968). Check your callbacks.\n",
      "2019-12-12 23:15:42.212722: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19815' and '__inference_standard_lstm_19472_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21340' both implement 'lstm_4d8eb3c8-a8a8-4135-a621-112c85d0b47b' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.91943, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.66_gc100_e100_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 334s - loss: 6.9489 - val_loss: 6.9194\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.91943 to 6.87328, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.66_gc100_e100_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 343s - loss: 6.8990 - val_loss: 6.8733\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.87328 to 6.81741, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.66_gc100_e100_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 346s - loss: 6.8403 - val_loss: 6.8174\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.81741 to 6.79458, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.66_gc100_e100_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 351s - loss: 6.7940 - val_loss: 6.7946\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.79458 to 6.72326, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.66_gc100_e100_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 352s - loss: 6.7240 - val_loss: 6.7233\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.72326 to 6.71392, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.66_gc100_e100_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 346s - loss: 6.6618 - val_loss: 6.7139\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.71392 to 6.66333, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.66_gc100_e100_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 346s - loss: 6.6283 - val_loss: 6.6633\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.66333 to 6.58291, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.66_gc100_e100_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 355s - loss: 6.5907 - val_loss: 6.5829\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.58291\n",
      "177316/177316 - 352s - loss: 6.5448 - val_loss: 6.5922\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss improved from 6.58291 to 6.57141, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.66_gc100_e100_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 355s - loss: 6.5031 - val_loss: 6.5714\n",
      "[6.948923976215525, 6.898986865338828, 6.840333848585924, 6.793985193196155, 6.724001720537927, 6.661769566571125, 6.628281338182766, 6.590711091910347, 6.544817865961132, 6.503091334661981]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  3481.969544649124  epochs in 3535.627566576004 s\n",
      "Last train cost :  6.71349028011617\n",
      "recall :  0.05247067162631121\n",
      "precision :  0.08600953895071578\n",
      "sps :  0.06041335453100159\n",
      "Best  sps :  0.06041335453100159\n",
      "sps_short :  0.05592105263157895\n",
      "sps_long :  0.06461538461538462\n",
      "user_coverage :  0.5421303656597775\n",
      "item_coverage :  123\n",
      "total_item_coverage :  541\n",
      "uniq_rec :  264\n",
      "ndcg :  0.08894914567861698\n",
      "blockbuster_share :  0.4436229205175601\n",
      "intra_list_similarity :  7.751116265558287\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne3481.97_gc100_e100_h150_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 10 --r_l 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-13 00:09:07.465330: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-13 00:09:07.486722: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895480000 Hz\n",
      "2019-12-13 00:09:07.487088: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4123a30 executing computations on platform Host. Devices:\n",
      "2019-12-13 00:09:07.487126: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-13 00:09:15.333794: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7410_8009' and '__inference___backward_standard_lstm_7410_8009_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8146' both implement 'lstm_b7cdab12-cf37-429b-88ea-ecaf28534793' but their signatures do not match.\n",
      "2019-12-13 00:09:15.816095: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.317908). Check your callbacks.\n",
      "2019-12-13 00:16:55.097576: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19815' and '__inference_standard_lstm_19472_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21340' both implement 'lstm_7d2e58ac-8874-4640-a92a-c8b5348021cf' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.90247, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.674_gc100_e100_h200_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 464s - loss: 6.9500 - val_loss: 6.9025\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.90247 to 6.88286, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.674_gc100_e100_h200_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 473s - loss: 6.9083 - val_loss: 6.8829\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.88286 to 6.83198, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.674_gc100_e100_h200_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 475s - loss: 6.8449 - val_loss: 6.8320\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.83198 to 6.80419, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.674_gc100_e100_h200_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 473s - loss: 6.8005 - val_loss: 6.8042\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.80419 to 6.79153, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.674_gc100_e100_h200_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 475s - loss: 6.7709 - val_loss: 6.7915\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.79153 to 6.74347, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.674_gc100_e100_h200_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 474s - loss: 6.7342 - val_loss: 6.7435\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 6.74347\n",
      "177316/177316 - 473s - loss: 6.6882 - val_loss: 6.8462\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.74347 to 6.64793, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.674_gc100_e100_h200_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 473s - loss: 6.6446 - val_loss: 6.6479\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.64793 to 6.63865, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.674_gc100_e100_h200_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 472s - loss: 6.6058 - val_loss: 6.6387\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss improved from 6.63865 to 6.60315, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.674_gc100_e100_h200_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 474s - loss: 6.5613 - val_loss: 6.6032\n",
      "[6.949993521229914, 6.908290661842356, 6.844947410120868, 6.800471860896851, 6.770854820364282, 6.734166562386457, 6.688171089863981, 6.64455774323128, 6.605826685845929, 6.561293713236331]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  4729.154653787613  epochs in 4784.154715299606 s\n",
      "Last train cost :  6.750857406901824\n",
      "recall :  0.05039002697398801\n",
      "precision :  0.08457869634340258\n",
      "sps :  0.046104928457869634\n",
      "Best  sps :  0.046104928457869634\n",
      "sps_short :  0.04276315789473684\n",
      "sps_long :  0.04923076923076923\n",
      "user_coverage :  0.5325914149443561\n",
      "item_coverage :  119\n",
      "total_item_coverage :  532\n",
      "uniq_rec :  243\n",
      "ndcg :  0.08944941592448698\n",
      "blockbuster_share :  0.4492481203007519\n",
      "intra_list_similarity :  7.453553702212628\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4729.155_gc100_e100_h200_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 10 --r_l 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-13 01:28:58.439685: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-13 01:28:58.462718: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895480000 Hz\n",
      "2019-12-13 01:28:58.463049: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x35db520 executing computations on platform Host. Devices:\n",
      "2019-12-13 01:28:58.463075: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-13 01:29:10.085149: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_14848_15447' and '__inference___backward_standard_lstm_14848_15447_specialized_for_StatefulPartitionedCall_1_at___inference_distributed_function_15611' both implement 'lstm_ad74eb5f-765f-4de1-add1-86f02651cd48' but their signatures do not match.\n",
      "2019-12-13 01:29:10.933988: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.611047). Check your callbacks.\n",
      "2019-12-13 01:35:02.412694: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_27280' and '__inference_standard_lstm_26937_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_30813' both implement 'lstm_ff584b62-a733-4139-97fa-96b91af12040' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.89146, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.716_gc100_e100_h100-50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 359s - loss: 6.9428 - val_loss: 6.8915\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.89146 to 6.85440, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.716_gc100_e100_h100-50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 358s - loss: 6.9053 - val_loss: 6.8544\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.85440 to 6.84302, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.716_gc100_e100_h100-50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 369s - loss: 6.8392 - val_loss: 6.8430\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.84302 to 6.80428, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.716_gc100_e100_h100-50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 370s - loss: 6.7991 - val_loss: 6.8043\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.80428 to 6.75022, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.716_gc100_e100_h100-50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 369s - loss: 6.7590 - val_loss: 6.7502\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.75022 to 6.70634, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.716_gc100_e100_h100-50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 369s - loss: 6.6947 - val_loss: 6.7063\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.70634 to 6.69720, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.716_gc100_e100_h100-50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 369s - loss: 6.6444 - val_loss: 6.6972\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.69720 to 6.60362, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.716_gc100_e100_h100-50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 369s - loss: 6.6052 - val_loss: 6.6036\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.60362\n",
      "177316/177316 - 370s - loss: 6.5670 - val_loss: 6.6184\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss improved from 6.60362 to 6.58463, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.716_gc100_e100_h100-50_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 370s - loss: 6.5263 - val_loss: 6.5846\n",
      "[6.942769839758316, 6.90531137194026, 6.839178731841704, 6.799084237401239, 6.759020056289222, 6.694744931322789, 6.644414877874867, 6.605240634068084, 6.567017613269627, 6.526335381195476]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  3674.1379075050354  epochs in 3780.067463159561 s\n",
      "Last train cost :  6.728311767496159\n",
      "recall :  0.05053418919227613\n",
      "precision :  0.08330683624801309\n",
      "sps :  0.06836248012718601\n",
      "Best  sps :  0.06836248012718601\n",
      "sps_short :  0.07236842105263158\n",
      "sps_long :  0.06461538461538462\n",
      "user_coverage :  0.5310015898251192\n",
      "item_coverage :  113\n",
      "total_item_coverage :  524\n",
      "uniq_rec :  231\n",
      "ndcg :  0.08687560582639553\n",
      "blockbuster_share :  0.45038167938931295\n",
      "intra_list_similarity :  7.7260029585703\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne3674.138_gc100_e100_h100-50_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 10 --r_l 100-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull origin tf2.0_tensorboard\n",
    "!git add .\n",
    "!git commit -m 'hidden_unit, 50-150-200,100-50 on remote_PC'\n",
    "!git push -u origin tf2.0_tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-13 02:32:06.773966: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-13 02:32:06.798748: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895480000 Hz\n",
      "2019-12-13 02:32:06.799078: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x463ca60 executing computations on platform Host. Devices:\n",
      "2019-12-13 02:32:06.799113: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-13 02:32:15.376687: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7390_7989_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8108' and '__inference___backward_standard_lstm_7390_7989' both implement 'lstm_bc6e6835-fd24-4c05-9c3f-732c525d6a57' but their signatures do not match.\n",
      "2019-12-13 02:32:15.798009: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.317231). Check your callbacks.\n",
      "2019-12-13 02:36:05.407225: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_19436_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21304' and '__inference_standard_lstm_19436' both implement 'lstm_db3eb624-2bd6-4ecc-9074-5bbd59e7245c' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.80510, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.673_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 234s - loss: 6.9004 - val_loss: 6.8051\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.80510 to 6.74858, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.673_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 237s - loss: 6.7871 - val_loss: 6.7486\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.74858 to 6.72847, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.673_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 238s - loss: 6.7379 - val_loss: 6.7285\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.72847 to 6.69804, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.673_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 237s - loss: 6.6957 - val_loss: 6.6980\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.69804 to 6.68258, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.673_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 236s - loss: 6.6618 - val_loss: 6.6826\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.68258 to 6.65406, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.673_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 237s - loss: 6.6316 - val_loss: 6.6541\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.65406 to 6.63996, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.673_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 236s - loss: 6.6050 - val_loss: 6.6400\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.63996 to 6.60451, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.673_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 237s - loss: 6.5797 - val_loss: 6.6045\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.60451\n",
      "177316/177316 - 236s - loss: 6.5541 - val_loss: 6.6425\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.60451\n",
      "177316/177316 - 236s - loss: 6.5299 - val_loss: 6.6855\n",
      "[6.900357414075562, 6.787100696174325, 6.737906932411296, 6.695735833090302, 6.661755012092779, 6.631556141537578, 6.605017030754624, 6.579655930363927, 6.554129551151297, 6.529854615081179]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  2365.5297708511353  epochs in 2420.360164165497 s\n",
      "Last train cost :  6.668306915673287\n",
      "recall :  0.04841186986597278\n",
      "precision :  0.07758346581876029\n",
      "sps :  0.058823529411764705\n",
      "Best  sps :  0.058823529411764705\n",
      "sps_short :  0.046052631578947366\n",
      "sps_long :  0.07076923076923076\n",
      "user_coverage :  0.505564387917329\n",
      "item_coverage :  114\n",
      "total_item_coverage :  488\n",
      "uniq_rec :  326\n",
      "ndcg :  0.08390476185460839\n",
      "blockbuster_share :  0.45081967213114754\n",
      "intra_list_similarity :  7.918241192505147\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2365.53_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 100  --min_iter 10 --r_emb 100 --r_emb_opt lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-13 03:12:40.393269: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-13 03:12:40.418652: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895480000 Hz\n",
      "2019-12-13 03:12:40.418941: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4b71c30 executing computations on platform Host. Devices:\n",
      "2019-12-13 03:12:40.418964: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-13 03:12:50.644833: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7390_7989_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8108' and '__inference___backward_standard_lstm_7390_7989' both implement 'lstm_65d080f3-10e0-475e-8553-6909c9458674' but their signatures do not match.\n",
      "2019-12-13 03:12:51.127160: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.304228). Check your callbacks.\n",
      "2019-12-13 03:20:08.748549: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_19436_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21304' and '__inference_standard_lstm_19436' both implement 'lstm_e7059e0e-4b2a-423b-871a-6053f100816f' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.91425, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.801_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 443s - loss: 6.9454 - val_loss: 6.9143\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.91425 to 6.84656, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.801_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 455s - loss: 6.8935 - val_loss: 6.8466\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.84656 to 6.76982, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.801_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 453s - loss: 6.8005 - val_loss: 6.7698\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.76982 to 6.74635, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.801_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 454s - loss: 6.7578 - val_loss: 6.7464\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.74635 to 6.73093, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.801_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 453s - loss: 6.7150 - val_loss: 6.7309\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 6.73093\n",
      "177316/177316 - 454s - loss: 6.6764 - val_loss: 6.7339\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.73093 to 6.67005, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.801_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 454s - loss: 6.6436 - val_loss: 6.6701\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.67005 to 6.64173, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.801_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 454s - loss: 6.6152 - val_loss: 6.6417\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.64173\n",
      "177316/177316 - 455s - loss: 6.5882 - val_loss: 6.6641\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.64173\n",
      "177316/177316 - 454s - loss: 6.5615 - val_loss: 6.6427\n",
      "[6.945405727822683, 6.893454372467363, 6.800452385085556, 6.757756685086012, 6.714971986043171, 6.676373286353638, 6.643619679515077, 6.615188254426712, 6.588156770537381, 6.561451049576988]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  4530.497527122498  epochs in 4585.971291303635 s\n",
      "Last train cost :  6.719683019691457\n",
      "recall :  0.049383290601690916\n",
      "precision :  0.08044515103338666\n",
      "sps :  0.06359300476947535\n",
      "Best  sps :  0.06359300476947535\n",
      "sps_short :  0.05263157894736842\n",
      "sps_long :  0.07384615384615385\n",
      "user_coverage :  0.505564387917329\n",
      "item_coverage :  115\n",
      "total_item_coverage :  506\n",
      "uniq_rec :  277\n",
      "ndcg :  0.08296079040690295\n",
      "blockbuster_share :  0.48023715415019763\n",
      "intra_list_similarity :  8.118530419313092\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4530.498_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 150 --min_iter 10 --r_emb 300 --r_emb_opt tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-13 04:29:15.680474: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-13 04:29:15.702689: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895480000 Hz\n",
      "2019-12-13 04:29:15.702968: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4c23b00 executing computations on platform Host. Devices:\n",
      "2019-12-13 04:29:15.703006: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-13 04:29:23.582262: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7410_8009' and '__inference___backward_standard_lstm_7410_8009_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8146' both implement 'lstm_d52ca2e2-21ca-443d-811f-d021ecc5853d' but their signatures do not match.\n",
      "2019-12-13 04:29:24.089635: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.307070). Check your callbacks.\n",
      "2019-12-13 04:37:12.716595: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19815' and '__inference_standard_lstm_19472_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21340' both implement 'lstm_5a00af23-9527-429a-9796-2ff81cfd565e' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.90942, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.673_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 474s - loss: 6.9476 - val_loss: 6.9094\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.90942 to 6.85041, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.673_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 485s - loss: 6.8898 - val_loss: 6.8504\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.85041 to 6.81522, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.673_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 484s - loss: 6.8228 - val_loss: 6.8152\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.81522 to 6.79324, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.673_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 488s - loss: 6.7895 - val_loss: 6.7932\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.79324 to 6.73376, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.673_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 486s - loss: 6.7510 - val_loss: 6.7338\n",
      "Epoch 6/10\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 150 --min_iter 10 --r_emb 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 150 --min_iter 10 --r_emb 300 --r_emb_opt lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 150 --min_iter 10 --r_emb 300 --r_emb_opt tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull origin tf2.0_tensorboard\n",
    "!git add .\n",
    "!git commit -m 'three embedding methods again on remote_PC'\n",
    "!git push -u origin tf2.0_tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 100 --r_l 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_remote_env_py3",
   "language": "python",
   "name": "my_remote_env_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
