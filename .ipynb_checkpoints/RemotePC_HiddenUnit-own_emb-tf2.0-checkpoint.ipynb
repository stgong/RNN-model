{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.fit() fine tune the RNN hidden layer parameter\n",
    "#### layers = [200, 250, 300,'200-100','300-200','200-100-50', '300-200-100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "!python -V\n",
    "!git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-12 19:45:34.142194: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-12 19:45:34.474755: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895480000 Hz\n",
      "2019-12-12 19:45:34.475774: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x52655f0 executing computations on platform Host. Devices:\n",
      "2019-12-12 19:45:34.475822: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-12 19:45:49.926437: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7410_8009' and '__inference___backward_standard_lstm_7410_8009_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8146' both implement 'lstm_ef0c66b6-8401-4f04-abeb-13d02c4a7d3e' but their signatures do not match.\n",
      "2019-12-12 19:45:53.272353: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.375420). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.122670). Check your callbacks.\n",
      "2019-12-12 19:49:52.830400: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19815' and '__inference_standard_lstm_19472_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21340' both implement 'lstm_4790ceda-558a-4753-96b2-35cac65c5733' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.89269, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 249s - loss: 6.9481 - val_loss: 6.8927\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.89269 to 6.84715, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.8792 - val_loss: 6.8472\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.84715 to 6.80179, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 247s - loss: 6.8142 - val_loss: 6.8018\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.80179 to 6.75154, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 254s - loss: 6.7803 - val_loss: 6.7515\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.75154\n",
      "177316/177316 - 249s - loss: 6.7336 - val_loss: 6.7557\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.75154 to 6.71344, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 249s - loss: 6.6774 - val_loss: 6.7134\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.71344 to 6.65282, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 250s - loss: 6.6374 - val_loss: 6.6528\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.65282 to 6.61956, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 249s - loss: 6.6015 - val_loss: 6.6196\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.61956 to 6.59987, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 252s - loss: 6.5606 - val_loss: 6.5999\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.59987\n",
      "177316/177316 - 251s - loss: 6.5231 - val_loss: 6.6041\n",
      "[6.94811860379506, 6.879202375879046, 6.814226186365032, 6.78034038051471, 6.73357450857457, 6.677416436217038, 6.637433948715631, 6.6015215811458035, 6.560601436996899, 6.523124260616167]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  2498.0048644542694  epochs in 2552.22132730484 s\n",
      "Last train cost :  6.7155559718819955\n",
      "recall :  0.04926736139584846\n",
      "precision :  0.08028616852146298\n",
      "sps :  0.05087440381558029\n",
      "Best  sps :  0.05087440381558029\n",
      "sps_short :  0.046052631578947366\n",
      "sps_long :  0.055384615384615386\n",
      "user_coverage :  0.534181240063593\n",
      "item_coverage :  115\n",
      "total_item_coverage :  505\n",
      "uniq_rec :  249\n",
      "ndcg :  0.08527619516459846\n",
      "blockbuster_share :  0.45544554455445546\n",
      "intra_list_similarity :  7.485150522473445\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2498.005_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 10 --r_l 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-12 20:30:16.502398: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-12 20:30:16.526705: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895480000 Hz\n",
      "2019-12-12 20:30:16.527072: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x414fde0 executing computations on platform Host. Devices:\n",
      "2019-12-12 20:30:16.527106: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "['ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2498.005_gc100_e100_h100_Ug_lr0.1_nt1.hdf5']\n",
      "Opening file (1)\n",
      "Timer:  53.171163331\n",
      "-------------------\n",
      "( 1 / 1 ) results on ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2498.005_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "sps@10:  0.07631160572337042\n",
      "sps_short@10:  0.06774193548387097\n",
      "sps_long@10:  0.08463949843260188\n",
      "recall@10:  0.052245336584076915\n",
      "precision@10:  0.09236883942766332\n",
      "uniq_rec@10:  287\n",
      "total_item_coverage@10:  581\n",
      "item_coverage@10:  144\n",
      "user_coverage@10:  0.5500794912559619\n",
      "ndcg@10:  0.0981475700676602\n",
      "blockbuster_share@10:  0.40963855421686746\n",
      "intra_list_similarity@10:  7.241215887277673\n"
     ]
    }
   ],
   "source": [
    "!python test.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --r_l 100 -i 2498.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-12 20:36:15.960697: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-12 20:36:15.982705: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895480000 Hz\n",
      "2019-12-12 20:36:15.982972: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x40f2cc0 executing computations on platform Host. Devices:\n",
      "2019-12-12 20:36:15.982997: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/20\n",
      "2019-12-12 20:36:23.977181: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7410_8009' and '__inference___backward_standard_lstm_7410_8009_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8146' both implement 'lstm_8a956a3a-2aa4-4b44-9dec-4f22c3958278' but their signatures do not match.\n",
      "2019-12-12 20:36:24.422067: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.328388). Check your callbacks.\n",
      "2019-12-12 20:40:22.207801: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19815' and '__inference_standard_lstm_19472_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21340' both implement 'lstm_0df19514-f882-4be9-aa12-91bed14ae6ae' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.89269, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 242s - loss: 6.9481 - val_loss: 6.8927\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.89269 to 6.84715, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 247s - loss: 6.8792 - val_loss: 6.8472\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.84715 to 6.80179, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.8142 - val_loss: 6.8018\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.80179 to 6.75154, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 245s - loss: 6.7803 - val_loss: 6.7515\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.75154\n",
      "177316/177316 - 246s - loss: 6.7336 - val_loss: 6.7557\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.75154 to 6.71344, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 244s - loss: 6.6774 - val_loss: 6.7134\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.71344 to 6.65282, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.6374 - val_loss: 6.6528\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.65282 to 6.61956, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 244s - loss: 6.6015 - val_loss: 6.6196\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.61956 to 6.59987, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.5606 - val_loss: 6.5999\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.59987\n",
      "177316/177316 - 244s - loss: 6.5231 - val_loss: 6.6041\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 00011: val_loss improved from 6.59987 to 6.58941, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 245s - loss: 6.4866 - val_loss: 6.5894\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 00012: val_loss improved from 6.58941 to 6.53589, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 245s - loss: 6.4484 - val_loss: 6.5359\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 00013: val_loss improved from 6.53589 to 6.52278, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 245s - loss: 6.4152 - val_loss: 6.5228\n",
      "Epoch 14/20\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 6.52278\n",
      "177316/177316 - 245s - loss: 6.3863 - val_loss: 6.5365\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 6.52278\n",
      "177316/177316 - 244s - loss: 6.3583 - val_loss: 6.5455\n",
      "Epoch 16/20\n",
      "\n",
      "Epoch 00016: val_loss improved from 6.52278 to 6.51651, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 245s - loss: 6.3304 - val_loss: 6.5165\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 6.51651\n",
      "177316/177316 - 244s - loss: 6.3044 - val_loss: 6.5349\n",
      "Epoch 18/20\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 6.51651\n",
      "177316/177316 - 245s - loss: 6.2798 - val_loss: 6.5217\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 00019: val_loss improved from 6.51651 to 6.51573, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 247s - loss: 6.2567 - val_loss: 6.5157\n",
      "Epoch 20/20\n",
      "\n",
      "Epoch 00020: val_loss improved from 6.51573 to 6.51077, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.2328 - val_loss: 6.5108\n",
      "[6.94811860379506, 6.879202375879046, 6.814226186365032, 6.78034038051471, 6.73357450857457, 6.677416436217038, 6.637433948715631, 6.6015215811458035, 6.560601436996899, 6.523124260616167, 6.486643334014204, 6.448387707736491, 6.41520447976165, 6.386331007566622, 6.3582913070704015, 6.330447896064886, 6.3043580901257315, 6.279755824810895, 6.2566592434574595, 6.232819713399854]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  4903.255256414413  epochs in 4956.018971204758 s\n",
      "Last train cost :  6.532722916141408\n",
      "recall :  0.05450064628948946\n",
      "precision :  0.08934817170111328\n",
      "sps :  0.07313195548489666\n",
      "Best  sps :  0.07313195548489666\n",
      "sps_short :  0.06907894736842106\n",
      "sps_long :  0.07692307692307693\n",
      "user_coverage :  0.5453100158982512\n",
      "item_coverage :  191\n",
      "total_item_coverage :  562\n",
      "uniq_rec :  581\n",
      "ndcg :  0.0928241509880779\n",
      "blockbuster_share :  0.37544483985765126\n",
      "intra_list_similarity :  6.760951503581973\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4903.255_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 20 --r_l 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-12 22:02:35.470138: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-12 22:02:35.494672: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895480000 Hz\n",
      "2019-12-12 22:02:35.494991: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x42a8ee0 executing computations on platform Host. Devices:\n",
      "2019-12-12 22:02:35.495022: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "['ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4903.255_gc100_e100_h100_Ug_lr0.1_nt1.hdf5']\n",
      "Opening file (1)\n",
      "Timer:  54.115255055\n",
      "-------------------\n",
      "( 1 / 1 ) results on ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4903.255_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "sps@10:  0.08267090620031796\n",
      "sps_short@10:  0.06774193548387097\n",
      "sps_long@10:  0.09717868338557993\n",
      "recall@10:  0.05231770021490292\n",
      "precision@10:  0.09220985691573963\n",
      "uniq_rec@10:  633\n",
      "total_item_coverage@10:  580\n",
      "item_coverage@10:  224\n",
      "user_coverage@10:  0.5453100158982512\n",
      "ndcg@10:  0.09702003211070638\n",
      "blockbuster_share@10:  0.3603448275862069\n",
      "intra_list_similarity@10:  6.463133680289377\n"
     ]
    }
   ],
   "source": [
    "!python test.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --r_l 100 -i 4903.255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 4, done.\u001b[K\n",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 4 (delta 0), reused 2 (delta 0), pack-reused 0\u001b[K\n",
      "Entpacke Objekte: 100% (4/4), Fertig.\n",
      "Von https://github.com/stgong/RNN-model\n",
      " * branch            tf2.0_tensorboard -> FETCH_HEAD\n",
      "   52be3bd..2487d63  tf2.0_tensorboard -> origin/tf2.0_tensorboard\n",
      "Aktualisiere 52be3bd..2487d63\n",
      "Fast-forward\n",
      " ...s_tensorboard run on tf.v1_all-checkpoint.ipynb | 369 \u001b[32m+++++++++++++++++++++\u001b[m\n",
      " TestingResuts_tensorboard run on tf.v1_all.ipynb   | 190 \u001b[32m+++++++++++\u001b[m\n",
      " 2 files changed, 559 insertions(+)\n",
      " create mode 100644 .ipynb_checkpoints/TestingResuts_tensorboard run on tf.v1_all-checkpoint.ipynb\n",
      " create mode 100644 TestingResuts_tensorboard run on tf.v1_all.ipynb\n",
      "[tf2.0_tensorboard 5a1ade6] emb100h100 epoch 20 train on remote_PC\n",
      " Committer: nicolakang <nicolakang@mailbox.tu-berlin.de>\n",
      "Ihr Name und E-Mail Adresse wurden automatisch auf Basis\n",
      "Ihres Benutzer- und Rechnernamens konfiguriert. Bitte prüfen Sie, dass\n",
      "diese zutreffend sind. Sie können diese Meldung unterdrücken, indem Sie\n",
      "diese explizit setzen:\n",
      "\n",
      "    git config --global user.name \"Ihr Name\"\n",
      "    git config --global user.email ihre@emailadresse.de\n",
      "\n",
      "Nachdem Sie das getan haben, können Sie Ihre Identität für diesen Commit ändern:\n",
      "\n",
      "    git commit --amend --reset-author\n",
      "\n",
      " 17 files changed, 768 insertions(+), 4 deletions(-)\n",
      " rename .ipynb_checkpoints/{LocalVirtual-HiddenUnit-own_emb-b4tensorborad-checkpoint.ipynb => LocalVirtual-HiddenUnit-own_emb-tf2.0-checkpoint.ipynb} (100%)\n",
      " create mode 100644 .ipynb_checkpoints/RemotePC_HiddenUnit-own_emb-tf2.0-checkpoint.ipynb\n",
      " rename LocalVirtual-HiddenUnit-own_emb-b4tensorborad.ipynb => LocalVirtual-HiddenUnit-own_emb-tf2.0.ipynb (99%)\n",
      " create mode 100644 RemotePC_HiddenUnit-own_emb-tf2.0.ipynb\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.666_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2498.005_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4903.255_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne5.181_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 logs/20191212-194534/train/events.out.tfevents.1576176345.tintel206d3.20645.2278.v2\n",
      " create mode 100644 logs/20191212-194534/train/events.out.tfevents.1576176353.tintel206d3.profile-empty\n",
      " create mode 100644 logs/20191212-194534/train/plugins/profile/2019-12-12_19-45-53/local.trace\n",
      " create mode 100644 logs/20191212-194534/validation/events.out.tfevents.1576176594.tintel206d3.20645.21407.v2\n",
      " create mode 100644 logs/20191212-203615/train/events.out.tfevents.1576179380.tintel206d3.21897.2278.v2\n",
      " create mode 100644 logs/20191212-203615/train/events.out.tfevents.1576179385.tintel206d3.profile-empty\n",
      " create mode 100644 logs/20191212-203615/train/plugins/profile/2019-12-12_20-36-25/local.trace\n",
      " create mode 100644 logs/20191212-203615/validation/events.out.tfevents.1576179622.tintel206d3.21897.21407.v2\n",
      "Zähle Objekte: 33, Fertig.\n",
      "Delta compression using up to 4 threads.\n",
      "Komprimiere Objekte: 100% (25/25), Fertig.\n",
      "Schreibe Objekte: 100% (33/33), 9.91 MiB | 4.38 MiB/s, Fertig.\n",
      "Total 33 (delta 9), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (9/9), completed with 5 local objects.\u001b[K\n",
      "To https://github.com/stgong/RNN-model.git\n",
      "   2487d63..5a1ade6  tf2.0_tensorboard -> tf2.0_tensorboard\n",
      "Branch 'tf2.0_tensorboard' folgt nun Remote-Branch 'tf2.0_tensorboard' von 'origin'.\n"
     ]
    }
   ],
   "source": [
    "!git pull origin tf2.0_tensorboard\n",
    "!git add .\n",
    "!git commit -m 'emb100h100 epoch 20 train on remote_PC'\n",
    "!git push -u origin tf2.0_tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 10 --r_l 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python test.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --r_l 150 -i 3781.422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can the BEST SPS from h150 trained from local pycharm be reproduced now in virtualenv? \n",
    "# worse than h= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 10 --r_l 100-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 10 --r_l 100-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_remote_env_py3",
   "language": "python",
   "name": "my_remote_env_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
