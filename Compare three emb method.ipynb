{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.fit() fine tune the RNN hidden layer parameter\n",
    "#### layers = [200, 250, 300,'200-100','300-200','200-100-50', '300-200-100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.9\n",
      "2.0.0\n",
      "Using TensorFlow backend.\n",
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "!python -V\n",
    "!python -c 'import tensorflow as tf; print(tf.__version__)'\n",
    "!python -c 'import keras; print(keras.__version__)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 15:54:07.833364: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 15:54:08.287182: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 15:54:08.287974: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4aa8730 executing computations on platform Host. Devices:\n",
      "2019-12-08 15:54:08.288015: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 15:54:21.409023: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_with_fallback_5815_7274' and '__inference___backward_standard_lstm_7392_7991_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8128' both implement 'lstm_7785e9da-2736-4568-83d9-ae5761a6bcfe' but their signatures do not match.\n",
      "2019-12-08 15:58:19.670679: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_19446' and '__inference_standard_lstm_19446_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21314' both implement 'lstm_170e8dd6-706a-45c7-be9e-bfbdd1728e8e' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.89269, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 243s - loss: 6.9481 - val_loss: 6.8927\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.89269 to 6.84715, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 248s - loss: 6.8792 - val_loss: 6.8472\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.84715 to 6.80179, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 242s - loss: 6.8142 - val_loss: 6.8018\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.80179 to 6.75154, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.7803 - val_loss: 6.7515\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.75154\n",
      "177316/177316 - 246s - loss: 6.7336 - val_loss: 6.7557\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.75154 to 6.71344, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 244s - loss: 6.6774 - val_loss: 6.7134\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.71344 to 6.65282, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 241s - loss: 6.6374 - val_loss: 6.6528\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.65282 to 6.61956, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 242s - loss: 6.6015 - val_loss: 6.6196\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.61956 to 6.59987, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 241s - loss: 6.5606 - val_loss: 6.5999\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.59987\n",
      "177316/177316 - 241s - loss: 6.5231 - val_loss: 6.6041\n",
      "[6.94811860379506, 6.879202375879046, 6.814226186365032, 6.78034038051471, 6.73357450857457, 6.677416436217038, 6.637433948715631, 6.6015215811458035, 6.560601436996899, 6.523124260616167]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  2434.3624789714813  epochs in 2487.863559484482 s\n",
      "Last train cost :  6.7155559718819955\n",
      "recall :  0.04926736139584846\n",
      "precision :  0.08028616852146298\n",
      "sps :  0.05087440381558029\n",
      "Best  sps :  0.05087440381558029\n",
      "user_coverage :  0.534181240063593\n",
      "item_coverage :  115\n",
      "ndcg :  0.08527619516459846\n",
      "blockbuster_share :  0.45544554455445546\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2434.362_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 10 --r_l 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 16:35:51.933258: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 16:35:51.955102: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 16:35:51.955487: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x45ffb60 executing computations on platform Host. Devices:\n",
      "2019-12-08 16:35:51.955512: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 16:35:59.721389: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_with_fallback_5815_7274' and '__inference___backward_standard_lstm_7392_7991_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8128' both implement 'lstm_d1d22693-0e96-422a-80aa-cd579da21dbc' but their signatures do not match.\n",
      "2019-12-08 16:39:57.143985: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_19446' and '__inference_standard_lstm_19446_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21314' both implement 'lstm_163e9693-cbdd-42b9-8109-17aff02187e6' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.89269, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 241s - loss: 6.9481 - val_loss: 6.8927\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.89269 to 6.84715, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.8792 - val_loss: 6.8472\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.84715 to 6.80179, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 248s - loss: 6.8142 - val_loss: 6.8018\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.80179 to 6.75154, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 248s - loss: 6.7803 - val_loss: 6.7515\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.75154\n",
      "177316/177316 - 247s - loss: 6.7336 - val_loss: 6.7557\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.75154 to 6.71344, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 248s - loss: 6.6774 - val_loss: 6.7134\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.71344 to 6.65282, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 250s - loss: 6.6374 - val_loss: 6.6528\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.65282 to 6.61956, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 249s - loss: 6.6015 - val_loss: 6.6196\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.61956 to 6.59987, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 252s - loss: 6.5606 - val_loss: 6.5999\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.59987\n",
      "177316/177316 - 248s - loss: 6.5231 - val_loss: 6.6041\n",
      "[6.94811860379506, 6.879202375879046, 6.814226186365032, 6.78034038051471, 6.73357450857457, 6.677416436217038, 6.637433948715631, 6.6015215811458035, 6.560601436996899, 6.523124260616167]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  2478.666837453842  epochs in 2530.4522364139557 s\n",
      "Last train cost :  6.7155559718819955\n",
      "recall :  0.04926736139584846\n",
      "precision :  0.08028616852146298\n",
      "sps :  0.05087440381558029\n",
      "Best  sps :  0.05087440381558029\n",
      "user_coverage :  0.534181240063593\n",
      "item_coverage :  115\n",
      "ndcg :  0.08527619516459846\n",
      "blockbuster_share :  0.45544554455445546\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2478.667_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 10 --r_l 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 17:34:08.532884: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 17:34:08.555037: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 17:34:08.555368: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3a404b0 executing computations on platform Host. Devices:\n",
      "2019-12-08 17:34:08.555398: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 17:34:16.831924: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7372_7971_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8090' and '__inference___backward_standard_lstm_7372_7971' both implement 'lstm_ca7d74f5-8966-4d30-a3d0-8c91dc5518f2' but their signatures do not match.\n",
      "2019-12-08 17:38:08.120581: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19753' and '__inference_standard_lstm_19410_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21278' both implement 'lstm_6b1aa37b-2106-4db4-95ff-f9209658ce8f' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.80510, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 235s - loss: 6.9004 - val_loss: 6.8051\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.80510 to 6.74858, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 242s - loss: 6.7871 - val_loss: 6.7486\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.74858 to 6.72847, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.7379 - val_loss: 6.7285\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.72847 to 6.69804, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 244s - loss: 6.6957 - val_loss: 6.6980\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.69804 to 6.68258, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 242s - loss: 6.6618 - val_loss: 6.6826\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.68258 to 6.65406, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 242s - loss: 6.6316 - val_loss: 6.6541\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.65406 to 6.63996, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 243s - loss: 6.6050 - val_loss: 6.6400\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.63996 to 6.60451, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 243s - loss: 6.5797 - val_loss: 6.6045\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.60451\n",
      "177316/177316 - 244s - loss: 6.5541 - val_loss: 6.6425\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.60451\n",
      "177316/177316 - 242s - loss: 6.5299 - val_loss: 6.6855\n",
      "[6.900357414075562, 6.787100696174325, 6.737906932411296, 6.695735833090302, 6.661755012092779, 6.631556141537578, 6.605017030754624, 6.579655930363927, 6.554129551151297, 6.529854615081179]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  2422.526834487915  epochs in 2476.2656564712524 s\n",
      "Last train cost :  6.668306915673287\n",
      "recall :  0.04841186986597278\n",
      "precision :  0.07758346581876029\n",
      "sps :  0.058823529411764705\n",
      "Best  sps :  0.058823529411764705\n",
      "user_coverage :  0.505564387917329\n",
      "item_coverage :  114\n",
      "ndcg :  0.08390476185460839\n",
      "blockbuster_share :  0.45081967213114754\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2422.527_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 100  --min_iter 10 --r_emb 100 --r_emb_opt lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 18:27:50.688075: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 18:27:50.711084: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 18:27:50.711400: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3a21750 executing computations on platform Host. Devices:\n",
      "2019-12-08 18:27:50.711426: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 18:27:58.865701: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7372_7971_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8090' and '__inference___backward_standard_lstm_7372_7971' both implement 'lstm_de970266-ff0e-44bc-aae5-3c26c3036a8c' but their signatures do not match.\n",
      "2019-12-08 18:31:49.505941: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19753' and '__inference_standard_lstm_19410_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21278' both implement 'lstm_929bffde-54a9-4807-a465-d8605a0ef50c' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.85168, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.825_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 234s - loss: 6.9328 - val_loss: 6.8517\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.85168 to 6.76717, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.825_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 240s - loss: 6.8109 - val_loss: 6.7672\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.76717 to 6.76570, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.825_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 241s - loss: 6.7748 - val_loss: 6.7657\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.76570 to 6.73645, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.825_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 242s - loss: 6.7466 - val_loss: 6.7364\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.73645\n",
      "177316/177316 - 237s - loss: 6.7159 - val_loss: 6.7431\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.73645 to 6.73055, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.825_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 243s - loss: 6.6953 - val_loss: 6.7306\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.73055 to 6.70131, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.825_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 243s - loss: 6.6756 - val_loss: 6.7013\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.70131 to 6.68020, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.825_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 245s - loss: 6.6563 - val_loss: 6.6802\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.68020\n",
      "177316/177316 - 239s - loss: 6.6379 - val_loss: 6.7045\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.68020\n",
      "177316/177316 - 237s - loss: 6.6192 - val_loss: 6.7046\n",
      "[6.932848278541241, 6.81093351899436, 6.774789036348899, 6.746568455035963, 6.715921419597139, 6.695346635480159, 6.67562738331148, 6.656339929848705, 6.6378877531729445, 6.61918183662139]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  2402.5848517417908  epochs in 2457.0072586536407 s\n",
      "Last train cost :  6.726544424695229\n",
      "recall :  0.0498946175127992\n",
      "precision :  0.08012718600953932\n",
      "sps :  0.05405405405405406\n",
      "Best  sps :  0.05405405405405406\n",
      "user_coverage :  0.5310015898251192\n",
      "item_coverage :  78\n",
      "ndcg :  0.08647292219359609\n",
      "blockbuster_share :  0.5634920634920635\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2402.585_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 100  --min_iter 10 --r_emb 100 --r_emb_opt tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 19:16:04.226925: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 19:16:04.251104: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 19:16:04.251424: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x49b5410 executing computations on platform Host. Devices:\n",
      "2019-12-08 19:16:04.251450: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 19:16:11.886578: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_with_fallback_5815_7274' and '__inference___backward_standard_lstm_7392_7991_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8128' both implement 'lstm_186f6af0-d18d-4ced-97cb-fde364df7541' but their signatures do not match.\n",
      "2019-12-08 19:21:41.539239: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_19446' and '__inference_standard_lstm_19446_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21314' both implement 'lstm_e2c8a813-a935-4718-93b7-290ed9c7c522' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.90929, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 334s - loss: 6.9483 - val_loss: 6.9093\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.90929 to 6.86318, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 325s - loss: 6.8983 - val_loss: 6.8632\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.86318 to 6.80928, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 326s - loss: 6.8290 - val_loss: 6.8093\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.80928 to 6.76434, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 329s - loss: 6.7848 - val_loss: 6.7643\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.76434 to 6.72089, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 327s - loss: 6.7221 - val_loss: 6.7209\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.72089 to 6.70573, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 327s - loss: 6.6570 - val_loss: 6.7057\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.70573 to 6.67620, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 329s - loss: 6.6163 - val_loss: 6.6762\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.67620 to 6.59822, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 327s - loss: 6.5794 - val_loss: 6.5982\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.59822\n",
      "177316/177316 - 327s - loss: 6.5409 - val_loss: 6.6057\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss improved from 6.59822 to 6.56253, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 327s - loss: 6.5026 - val_loss: 6.5625\n",
      "[6.948282116859813, 6.898323431890401, 6.829027530468196, 6.784833767887982, 6.722064285490874, 6.657030629682499, 6.616250094340375, 6.579442675941036, 6.5409266300120095, 6.502640888287516]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  3277.95161151886  epochs in 3334.039526462555 s\n",
      "Last train cost :  6.7078822050860705\n",
      "recall :  0.04909873013970709\n",
      "precision :  0.08092209856915772\n",
      "sps :  0.05087440381558029\n",
      "Best  sps :  0.05087440381558029\n",
      "user_coverage :  0.5246422893481717\n",
      "item_coverage :  128\n",
      "ndcg :  0.0851564145453465\n",
      "blockbuster_share :  0.40471512770137524\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne3277.952_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 100 --min_iter 10 --r_emb 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 20:11:45.189906: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 20:11:45.211070: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 20:11:45.211406: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x50b43d0 executing computations on platform Host. Devices:\n",
      "2019-12-08 20:11:45.211448: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 20:11:53.333098: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7372_7971_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8090' and '__inference___backward_standard_lstm_7372_7971' both implement 'lstm_7223148f-6b2d-4ced-b2a6-191170b3cc44' but their signatures do not match.\n",
      "2019-12-08 20:17:01.971088: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19753' and '__inference_standard_lstm_19410_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21278' both implement 'lstm_38637a0b-d8ce-4db5-8649-95b6a7f71e67' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.81266, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.796_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 313s - loss: 6.9083 - val_loss: 6.8127\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.81266 to 6.76192, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.796_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 313s - loss: 6.7868 - val_loss: 6.7619\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.76192 to 6.71104, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.796_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 313s - loss: 6.7312 - val_loss: 6.7110\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.71104 to 6.66162, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.796_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 312s - loss: 6.6825 - val_loss: 6.6616\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.66162\n",
      "177316/177316 - 313s - loss: 6.6446 - val_loss: 6.6664\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.66162 to 6.65946, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.796_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 313s - loss: 6.6103 - val_loss: 6.6595\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.65946 to 6.61444, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.796_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 313s - loss: 6.5794 - val_loss: 6.6144\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.61444 to 6.57498, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.796_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 315s - loss: 6.5484 - val_loss: 6.5750\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.57498\n",
      "177316/177316 - 312s - loss: 6.5178 - val_loss: 6.6069\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.57498\n",
      "177316/177316 - 312s - loss: 6.4888 - val_loss: 6.6843\n",
      "[6.908305372487587, 6.7867804313782205, 6.731160638769576, 6.682489847421039, 6.6445799570940505, 6.610251301337301, 6.579400194482146, 6.548414636985113, 6.517842042045178, 6.4887742018532375]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  3129.248851776123  epochs in 3181.8081562519073 s\n",
      "Last train cost :  6.649799862385345\n",
      "recall :  0.04613757759059107\n",
      "precision :  0.07392686804451536\n",
      "sps :  0.05405405405405406\n",
      "Best  sps :  0.05405405405405406\n",
      "user_coverage :  0.48012718600953896\n",
      "item_coverage :  104\n",
      "ndcg :  0.07968357917384924\n",
      "blockbuster_share :  0.4774193548387097\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne3129.249_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 100 --min_iter 10 --r_emb 300 --r_emb_opt lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 21:04:59.063751: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 21:04:59.087076: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 21:04:59.087472: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x489ede0 executing computations on platform Host. Devices:\n",
      "2019-12-08 21:04:59.087536: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 21:05:07.259273: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7372_7971_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8090' and '__inference___backward_standard_lstm_7372_7971' both implement 'lstm_3e31ddbe-f3b8-4527-9558-996ddf0bc8f4' but their signatures do not match.\n",
      "2019-12-08 21:10:23.609478: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19753' and '__inference_standard_lstm_19410_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21278' both implement 'lstm_4e0c3232-89b6-46c5-9167-2bbd277a554e' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.92423, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 320s - loss: 6.9468 - val_loss: 6.9242\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.92423 to 6.83542, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 319s - loss: 6.8919 - val_loss: 6.8354\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.83542 to 6.77275, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 320s - loss: 6.8113 - val_loss: 6.7728\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 6.77275\n",
      "177316/177316 - 319s - loss: 6.7708 - val_loss: 6.7803\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.77275 to 6.77171, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 320s - loss: 6.7390 - val_loss: 6.7717\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.77171 to 6.74518, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 319s - loss: 6.6991 - val_loss: 6.7452\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.74518 to 6.69791, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 320s - loss: 6.6685 - val_loss: 6.6979\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 6.69791\n",
      "177316/177316 - 318s - loss: 6.6388 - val_loss: 6.7110\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.69791 to 6.68109, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 316s - loss: 6.6115 - val_loss: 6.6811\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss improved from 6.68109 to 6.66849, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 318s - loss: 6.5860 - val_loss: 6.6685\n",
      "[6.946803747613978, 6.891933102280613, 6.8112969278990745, 6.77081582393972, 6.738979920508583, 6.699143124158094, 6.668547177750946, 6.638786378748302, 6.611497394177364, 6.585963078001684]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  3189.6059374809265  epochs in 3242.6474466323853 s\n",
      "Last train cost :  6.7363766675078365\n",
      "recall :  0.05131234977335264\n",
      "precision :  0.08203497615262358\n",
      "sps :  0.058823529411764705\n",
      "Best  sps :  0.058823529411764705\n",
      "user_coverage :  0.5166931637519873\n",
      "item_coverage :  102\n",
      "ndcg :  0.08617290132518132\n",
      "blockbuster_share :  0.5271317829457365\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne3189.606_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 100 --min_iter 10 --r_emb 300 --r_emb_opt tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 8, done.\u001b[K\n",
      "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
      "remote: Total 8 (delta 1), reused 4 (delta 1), pack-reused 0\u001b[K\n",
      "Entpacke Objekte: 100% (8/8), Fertig.\n",
      "Von https://github.com/stgong/RNN-model\n",
      " * branch            remote_PC  -> FETCH_HEAD\n",
      "   744da20..cc1ec5f  remote_PC  -> origin/remote_PC\n",
      "Aktualisiere 744da20..cc1ec5f\n",
      "Fast-forward\n",
      " ...g logs from local_virtual_env -checkpoint.ipynb | 424 \u001b[32m+++++++++++++++++++++\u001b[m\n",
      " ...EMB_Training logs from local_virtual_env .ipynb | 146 \u001b[32m+++++++\u001b[m\n",
      " ..._bs32_ne2.549_gc100_e100_h100_Ug_lr0.1_nt1.hdf5 | Bin \u001b[31m0\u001b[m -> \u001b[32m3051712\u001b[m bytes\n",
      " ...32_ne3031.799_gc100_e100_h100_Ug_lr0.1_nt1.hdf5 | Bin \u001b[31m0\u001b[m -> \u001b[32m3051712\u001b[m bytes\n",
      " 4 files changed, 570 insertions(+)\n",
      " create mode 100644 .ipynb_checkpoints/OWN EMB_Training logs from local_virtual_env -checkpoint.ipynb\n",
      " create mode 100644 OWN EMB_Training logs from local_virtual_env .ipynb\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.549_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne3031.799_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "[remote_PC 7066391] Comparing three embedding methods with h100\n",
      " Committer: nicolakang <nicolakang@mailbox.tu-berlin.de>\n",
      "Ihr Name und E-Mail Adresse wurden automatisch auf Basis\n",
      "Ihres Benutzer- und Rechnernamens konfiguriert. Bitte prüfen Sie, dass\n",
      "diese zutreffend sind. Sie können diese Meldung unterdrücken, indem Sie\n",
      "diese explizit setzen:\n",
      "\n",
      "    git config --global user.name \"Ihr Name\"\n",
      "    git config --global user.email ihre@emailadresse.de\n",
      "\n",
      "Nachdem Sie das getan haben, können Sie Ihre Identität für diesen Commit ändern:\n",
      "\n",
      "    git commit --amend --reset-author\n",
      "\n",
      " 9 files changed, 262 insertions(+), 8 deletions(-)\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.768_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.796_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2402.585_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne3129.249_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne3189.606_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne3277.952_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "Zähle Objekte: 13, Fertig.\n",
      "Delta compression using up to 4 threads.\n",
      "Komprimiere Objekte: 100% (13/13), Fertig.\n",
      "Schreibe Objekte: 100% (13/13), 21.93 MiB | 2.33 MiB/s, Fertig.\n",
      "Total 13 (delta 6), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (6/6), completed with 4 local objects.\u001b[K\n",
      "To https://github.com/stgong/RNN-model.git\n",
      "   cc1ec5f..7066391  remote_PC -> remote_PC\n",
      "Branch 'remote_PC' folgt nun Remote-Branch 'remote_PC' von 'origin'.\n"
     ]
    }
   ],
   "source": [
    "!git pull origin remote_PC\n",
    "!git add .\n",
    "!git commit -m 'Comparing three embedding methods with h100'\n",
    "!git push -u origin remote_PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 21:59:34.214648: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 21:59:34.239133: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 21:59:34.239530: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x51134d0 executing computations on platform Host. Devices:\n",
      "2019-12-08 21:59:34.239562: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 21:59:41.922588: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_with_fallback_5815_7274' and '__inference___backward_standard_lstm_7392_7991_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8128' both implement 'lstm_a6903ffc-42c9-4a00-8f4a-bc3addac8933' but their signatures do not match.\n",
      "2019-12-08 22:07:30.012722: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_19446' and '__inference_standard_lstm_19446_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21314' both implement 'lstm_f6c131b2-61bf-45a7-b010-95deab18d34c' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.90942, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.684_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 473s - loss: 6.9476 - val_loss: 6.9094\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.90942 to 6.85041, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.684_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 487s - loss: 6.8898 - val_loss: 6.8504\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.85041 to 6.81522, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.684_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 482s - loss: 6.8228 - val_loss: 6.8152\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.81522 to 6.79324, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.684_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 484s - loss: 6.7895 - val_loss: 6.7932\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.79324 to 6.73376, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.684_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 483s - loss: 6.7510 - val_loss: 6.7338\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.73376 to 6.69175, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.684_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 485s - loss: 6.6904 - val_loss: 6.6918\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.69175 to 6.67185, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.684_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 486s - loss: 6.6368 - val_loss: 6.6718\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.67185 to 6.61932, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.684_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 485s - loss: 6.5931 - val_loss: 6.6193\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.61932 to 6.59603, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.684_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 487s - loss: 6.5505 - val_loss: 6.5960\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.59603\n",
      "177316/177316 - 486s - loss: 6.5098 - val_loss: 6.6277\n",
      "[6.94755002745527, 6.889830145857068, 6.8228079052049315, 6.789530963642124, 6.750955148898395, 6.690399640875076, 6.636765260033148, 6.593063113174657, 6.550456388822417, 6.50981352490552]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  4839.348731994629  epochs in 4894.851105928421 s\n",
      "Last train cost :  6.71811721188686\n",
      "recall :  0.04823075100386797\n",
      "precision :  0.0793322734499208\n",
      "sps :  0.06041335453100159\n",
      "Best  sps :  0.06041335453100159\n",
      "user_coverage :  0.4960254372019078\n",
      "item_coverage :  120\n",
      "ndcg :  0.08466972101191624\n",
      "blockbuster_share :  0.4348697394789579\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4839.349_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 150 --min_iter 10 --r_emb 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 23:21:17.980604: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 23:21:18.007118: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 23:21:18.007418: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x44f8030 executing computations on platform Host. Devices:\n",
      "2019-12-08 23:21:18.007449: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 23:21:26.375996: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7372_7971_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8090' and '__inference___backward_standard_lstm_7372_7971' both implement 'lstm_7200f13e-1e82-489e-b89e-06f42a20abe0' but their signatures do not match.\n",
      "2019-12-08 23:28:56.582881: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19753' and '__inference_standard_lstm_19410_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21278' both implement 'lstm_afbfe0e9-e97d-4f08-9181-35facbd4c0b0' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.82667, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.881_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 455s - loss: 6.9190 - val_loss: 6.8267\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.82667 to 6.75031, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.881_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 463s - loss: 6.7906 - val_loss: 6.7503\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.75031 to 6.71340, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.881_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 464s - loss: 6.7263 - val_loss: 6.7134\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.71340 to 6.65801, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.881_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 464s - loss: 6.6756 - val_loss: 6.6580\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.65801\n",
      "177316/177316 - 463s - loss: 6.6363 - val_loss: 6.6626\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.65801 to 6.65745, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.881_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 465s - loss: 6.5976 - val_loss: 6.6575\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.65745 to 6.61732, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.881_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 466s - loss: 6.5614 - val_loss: 6.6173\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.61732 to 6.56305, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.881_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 467s - loss: 6.5254 - val_loss: 6.5630\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.56305\n",
      "177316/177316 - 468s - loss: 6.4901 - val_loss: 6.5823\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.56305\n",
      "177316/177316 - 466s - loss: 6.4556 - val_loss: 6.6109\n",
      "[6.919032784500506, 6.790565801270802, 6.726263279643677, 6.675631176721085, 6.636314125848862, 6.597553234629145, 6.561423096274611, 6.525386727002255, 6.490121665105579, 6.455595248664519]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  4641.536967754364  epochs in 4697.521890640259 s\n",
      "Last train cost :  6.6377887139661045\n",
      "recall :  0.05032268296638274\n",
      "precision :  0.08124006359300515\n",
      "sps :  0.06518282988871224\n",
      "Best  sps :  0.06518282988871224\n",
      "user_coverage :  0.5325914149443561\n",
      "item_coverage :  131\n",
      "ndcg :  0.08266413121546494\n",
      "blockbuster_share :  0.4090019569471624\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4641.537_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 150 --min_iter 10 --r_emb 300 --r_emb_opt lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 00:39:43.242738: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-09 00:39:43.267066: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-09 00:39:43.267437: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3f3d100 executing computations on platform Host. Devices:\n",
      "2019-12-09 00:39:43.267482: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-09 00:39:51.438108: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7372_7971_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8090' and '__inference___backward_standard_lstm_7372_7971' both implement 'lstm_d757f045-83b8-4931-9e85-ce39331bc0d9' but their signatures do not match.\n",
      "2019-12-09 00:47:31.493604: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19753' and '__inference_standard_lstm_19410_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21278' both implement 'lstm_63b46c9a-1e43-401a-86dd-361bfbce251d' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.91425, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.785_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 464s - loss: 6.9454 - val_loss: 6.9143\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.91425 to 6.84656, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.785_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 470s - loss: 6.8935 - val_loss: 6.8466\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.84656 to 6.76982, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.785_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 477s - loss: 6.8005 - val_loss: 6.7698\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.76982 to 6.74635, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.785_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 478s - loss: 6.7578 - val_loss: 6.7464\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.74635 to 6.73093, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.785_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 478s - loss: 6.7150 - val_loss: 6.7309\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 6.73093\n",
      "177316/177316 - 481s - loss: 6.6764 - val_loss: 6.7339\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.73093 to 6.67005, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.785_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 480s - loss: 6.6436 - val_loss: 6.6701\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.67005 to 6.64173, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.785_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 478s - loss: 6.6152 - val_loss: 6.6417\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.64173\n",
      "177316/177316 - 479s - loss: 6.5882 - val_loss: 6.6641\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.64173\n",
      "177316/177316 - 476s - loss: 6.5615 - val_loss: 6.6427\n",
      "[6.945405727822683, 6.893454372467363, 6.800452385085556, 6.757756685086012, 6.714971986043171, 6.676373286353638, 6.643619679515077, 6.615188254426712, 6.588156770537381, 6.561451049576988]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  4762.485520839691  epochs in 4819.5845358371735 s\n",
      "Last train cost :  6.719683019691457\n",
      "recall :  0.049383290601690916\n",
      "precision :  0.08044515103338666\n",
      "sps :  0.06359300476947535\n",
      "Best  sps :  0.06359300476947535\n",
      "user_coverage :  0.505564387917329\n",
      "item_coverage :  115\n",
      "ndcg :  0.08296079040690295\n",
      "blockbuster_share :  0.48023715415019763\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4762.486_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 150 --min_iter 10 --r_emb 300 --r_emb_opt tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 14, done.\u001b[K\n",
      "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
      "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
      "remote: Total 14 (delta 7), reused 10 (delta 7), pack-reused 0\u001b[K\n",
      "Entpacke Objekte: 100% (14/14), Fertig.\n",
      "Von https://github.com/stgong/RNN-model\n",
      " * branch            remote_PC  -> FETCH_HEAD\n",
      "   7066391..a6759c8  remote_PC  -> origin/remote_PC\n",
      "Aktualisiere 7066391..a6759c8\n",
      "Fast-forward\n",
      " .DS_Store                                           | Bin \u001b[31m10244\u001b[m -> \u001b[32m10244\u001b[m bytes\n",
      " ks-cooks-1y/.DS_Store                               | Bin \u001b[31m14340\u001b[m -> \u001b[32m14340\u001b[m bytes\n",
      " ks-cooks-1yresults/.DS_Store                        | Bin \u001b[31m0\u001b[m -> \u001b[32m6148\u001b[m bytes\n",
      " ...s32_ne3031.799_gc100_e100_h100_Ug_lr0.1_nt1.hdf5 |   8 \u001b[32m++++++++\u001b[m\n",
      " logs                                                |  20 \u001b[32m++++++++++++\u001b[m\u001b[31m--------\u001b[m\n",
      " neural_networks/rnn_base.py                         |  18 \u001b[32m+++++++++++++\u001b[m\u001b[31m-----\u001b[m\n",
      " test.py                                             |   4 \u001b[32m++++\u001b[m\n",
      " 7 files changed, 37 insertions(+), 13 deletions(-)\n",
      " create mode 100644 ks-cooks-1yresults/.DS_Store\n",
      " create mode 100644 ks-cooks-1yresults/rnn_cce_ml60_bs32_ne3031.799_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "[remote_PC 09daaec] Comparing three embedding methods with h150\n",
      " Committer: nicolakang <nicolakang@mailbox.tu-berlin.de>\n",
      "Ihr Name und E-Mail Adresse wurden automatisch auf Basis\n",
      "Ihres Benutzer- und Rechnernamens konfiguriert. Bitte prüfen Sie, dass\n",
      "diese zutreffend sind. Sie können diese Meldung unterdrücken, indem Sie\n",
      "diese explizit setzen:\n",
      "\n",
      "    git config --global user.name \"Ihr Name\"\n",
      "    git config --global user.email ihre@emailadresse.de\n",
      "\n",
      "Nachdem Sie das getan haben, können Sie Ihre Identität für diesen Commit ändern:\n",
      "\n",
      "    git commit --amend --reset-author\n",
      "\n",
      " 7 files changed, 276 insertions(+), 9 deletions(-)\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.684_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.785_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.881_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4641.537_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4762.486_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne4839.349_gc100_e300_h150_Ug_lr0.1_nt1.hdf5\n",
      "Zähle Objekte: 11, Fertig.\n",
      "Delta compression using up to 4 threads.\n",
      "Komprimiere Objekte: 100% (11/11), Fertig.\n",
      "Schreibe Objekte: 100% (11/11), 32.43 MiB | 8.56 MiB/s, Fertig.\n",
      "Total 11 (delta 4), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
      "To https://github.com/stgong/RNN-model.git\n",
      "   a6759c8..09daaec  remote_PC -> remote_PC\n",
      "Branch 'remote_PC' folgt nun Remote-Branch 'remote_PC' von 'origin'.\n"
     ]
    }
   ],
   "source": [
    "!git pull origin remote_PC\n",
    "!git add .\n",
    "!git commit -m 'Comparing three embedding methods with h150'\n",
    "!git push -u origin remote_PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 17, done.\u001b[K\n",
      "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
      "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
      "remote: Total 17 (delta 9), reused 17 (delta 9), pack-reused 0\u001b[K\n",
      "Entpacke Objekte: 100% (17/17), Fertig.\n",
      "Von https://github.com/stgong/RNN-model\n",
      " * branch            remote_PC  -> FETCH_HEAD\n",
      "   09daaec..99332d8  remote_PC  -> origin/remote_PC\n",
      "Aktualisiere 09daaec..99332d8\n",
      "Checke Dateien aus: 100% (7/7), Fertig.\n",
      "Fast-forward\n",
      " ..._bs32_ne2.678_gc100_e100_h100_Ug_lr0.1_nt1.hdf5 | Bin \u001b[31m0\u001b[m -> \u001b[32m3052808\u001b[m bytes\n",
      " ...32_ne2674.222_gc100_e100_h100_Ug_lr0.1_nt1.hdf5 | Bin \u001b[31m0\u001b[m -> \u001b[32m3052808\u001b[m bytes\n",
      " ..._bs32_ne3.144_gc100_e100_h200_Ug_lr0.1_nt1.hdf5 | Bin \u001b[31m0\u001b[m -> \u001b[32m5518760\u001b[m bytes\n",
      " ...32_ne3031.799_gc100_e100_h100_Ug_lr0.1_nt1.hdf5 |   8 \u001b[31m---\u001b[m\n",
      " logs                                               |  79 \u001b[32m+++++++++++++++\u001b[m\u001b[31m------\u001b[m\n",
      " neural_networks/rnn_oh_keras.py                    |  12 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
      " virtualenv                                         |   6 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
      " 7 files changed, 66 insertions(+), 39 deletions(-)\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.678_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2674.222_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      " create mode 100644 ks-cooks-1y/models/rnn_cce_ml60_bs32_ne3.144_gc100_e100_h200_Ug_lr0.1_nt1.hdf5\n",
      " delete mode 100644 ks-cooks-1yresults/rnn_cce_ml60_bs32_ne3031.799_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "[remote_PC 271d5ec] Comparing three embedding methods with h150 emb 300 complete result\n",
      " Committer: nicolakang <nicolakang@mailbox.tu-berlin.de>\n",
      "Ihr Name und E-Mail Adresse wurden automatisch auf Basis\n",
      "Ihres Benutzer- und Rechnernamens konfiguriert. Bitte prüfen Sie, dass\n",
      "diese zutreffend sind. Sie können diese Meldung unterdrücken, indem Sie\n",
      "diese explizit setzen:\n",
      "\n",
      "    git config --global user.name \"Ihr Name\"\n",
      "    git config --global user.email ihre@emailadresse.de\n",
      "\n",
      "Nachdem Sie das getan haben, können Sie Ihre Identität für diesen Commit ändern:\n",
      "\n",
      "    git commit --amend --reset-author\n",
      "\n",
      " 2 files changed, 730 insertions(+), 18 deletions(-)\n",
      "Zähle Objekte: 5, Fertig.\n",
      "Delta compression using up to 4 threads.\n",
      "Komprimiere Objekte: 100% (5/5), Fertig.\n",
      "Schreibe Objekte: 100% (5/5), 8.75 KiB | 8.75 MiB/s, Fertig.\n",
      "Total 5 (delta 3), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (3/3), completed with 2 local objects.\u001b[K\n",
      "To https://github.com/stgong/RNN-model.git\n",
      "   99332d8..271d5ec  remote_PC -> remote_PC\n",
      "Branch 'remote_PC' folgt nun Remote-Branch 'remote_PC' von 'origin'.\n"
     ]
    }
   ],
   "source": [
    "!git pull origin remote_PC\n",
    "!git add .\n",
    "!git commit -m 'Comparing three embedding methods with h150 emb 300 complete result'\n",
    "!git push -u origin remote_PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-python3-virlenv",
   "language": "python",
   "name": "my-python3-virlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
