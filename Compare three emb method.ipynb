{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.fit() fine tune the RNN hidden layer parameter\n",
    "#### layers = [200, 250, 300,'200-100','300-200','200-100-50', '300-200-100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 15:54:07.833364: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 15:54:08.287182: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 15:54:08.287974: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4aa8730 executing computations on platform Host. Devices:\n",
      "2019-12-08 15:54:08.288015: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 15:54:21.409023: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_with_fallback_5815_7274' and '__inference___backward_standard_lstm_7392_7991_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8128' both implement 'lstm_7785e9da-2736-4568-83d9-ae5761a6bcfe' but their signatures do not match.\n",
      "2019-12-08 15:58:19.670679: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_19446' and '__inference_standard_lstm_19446_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21314' both implement 'lstm_170e8dd6-706a-45c7-be9e-bfbdd1728e8e' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.89269, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 243s - loss: 6.9481 - val_loss: 6.8927\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.89269 to 6.84715, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 248s - loss: 6.8792 - val_loss: 6.8472\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.84715 to 6.80179, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 242s - loss: 6.8142 - val_loss: 6.8018\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.80179 to 6.75154, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.7803 - val_loss: 6.7515\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.75154\n",
      "177316/177316 - 246s - loss: 6.7336 - val_loss: 6.7557\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.75154 to 6.71344, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 244s - loss: 6.6774 - val_loss: 6.7134\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.71344 to 6.65282, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 241s - loss: 6.6374 - val_loss: 6.6528\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.65282 to 6.61956, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 242s - loss: 6.6015 - val_loss: 6.6196\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.61956 to 6.59987, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.72_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 241s - loss: 6.5606 - val_loss: 6.5999\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.59987\n",
      "177316/177316 - 241s - loss: 6.5231 - val_loss: 6.6041\n",
      "[6.94811860379506, 6.879202375879046, 6.814226186365032, 6.78034038051471, 6.73357450857457, 6.677416436217038, 6.637433948715631, 6.6015215811458035, 6.560601436996899, 6.523124260616167]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  2434.3624789714813  epochs in 2487.863559484482 s\n",
      "Last train cost :  6.7155559718819955\n",
      "recall :  0.04926736139584846\n",
      "precision :  0.08028616852146298\n",
      "sps :  0.05087440381558029\n",
      "Best  sps :  0.05087440381558029\n",
      "user_coverage :  0.534181240063593\n",
      "item_coverage :  115\n",
      "ndcg :  0.08527619516459846\n",
      "blockbuster_share :  0.45544554455445546\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2434.362_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 10 --r_l 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 16:35:51.933258: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 16:35:51.955102: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 16:35:51.955487: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x45ffb60 executing computations on platform Host. Devices:\n",
      "2019-12-08 16:35:51.955512: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 16:35:59.721389: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_with_fallback_5815_7274' and '__inference___backward_standard_lstm_7392_7991_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8128' both implement 'lstm_d1d22693-0e96-422a-80aa-cd579da21dbc' but their signatures do not match.\n",
      "2019-12-08 16:39:57.143985: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_19446' and '__inference_standard_lstm_19446_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21314' both implement 'lstm_163e9693-cbdd-42b9-8109-17aff02187e6' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.89269, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 241s - loss: 6.9481 - val_loss: 6.8927\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.89269 to 6.84715, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.8792 - val_loss: 6.8472\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.84715 to 6.80179, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 248s - loss: 6.8142 - val_loss: 6.8018\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.80179 to 6.75154, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 248s - loss: 6.7803 - val_loss: 6.7515\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.75154\n",
      "177316/177316 - 247s - loss: 6.7336 - val_loss: 6.7557\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.75154 to 6.71344, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 248s - loss: 6.6774 - val_loss: 6.7134\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.71344 to 6.65282, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 250s - loss: 6.6374 - val_loss: 6.6528\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.65282 to 6.61956, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 249s - loss: 6.6015 - val_loss: 6.6196\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.61956 to 6.59987, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.708_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 252s - loss: 6.5606 - val_loss: 6.5999\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.59987\n",
      "177316/177316 - 248s - loss: 6.5231 - val_loss: 6.6041\n",
      "[6.94811860379506, 6.879202375879046, 6.814226186365032, 6.78034038051471, 6.73357450857457, 6.677416436217038, 6.637433948715631, 6.6015215811458035, 6.560601436996899, 6.523124260616167]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  2478.666837453842  epochs in 2530.4522364139557 s\n",
      "Last train cost :  6.7155559718819955\n",
      "recall :  0.04926736139584846\n",
      "precision :  0.08028616852146298\n",
      "sps :  0.05087440381558029\n",
      "Best  sps :  0.05087440381558029\n",
      "user_coverage :  0.534181240063593\n",
      "item_coverage :  115\n",
      "ndcg :  0.08527619516459846\n",
      "blockbuster_share :  0.45544554455445546\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2478.667_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_emb 100 --min_iter 10 --r_l 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 17:34:08.532884: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 17:34:08.555037: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 17:34:08.555368: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3a404b0 executing computations on platform Host. Devices:\n",
      "2019-12-08 17:34:08.555398: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 17:34:16.831924: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7372_7971_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8090' and '__inference___backward_standard_lstm_7372_7971' both implement 'lstm_ca7d74f5-8966-4d30-a3d0-8c91dc5518f2' but their signatures do not match.\n",
      "2019-12-08 17:38:08.120581: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19753' and '__inference_standard_lstm_19410_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21278' both implement 'lstm_6b1aa37b-2106-4db4-95ff-f9209658ce8f' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.80510, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 235s - loss: 6.9004 - val_loss: 6.8051\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.80510 to 6.74858, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 242s - loss: 6.7871 - val_loss: 6.7486\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.74858 to 6.72847, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 246s - loss: 6.7379 - val_loss: 6.7285\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.72847 to 6.69804, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 244s - loss: 6.6957 - val_loss: 6.6980\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.69804 to 6.68258, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 242s - loss: 6.6618 - val_loss: 6.6826\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.68258 to 6.65406, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 242s - loss: 6.6316 - val_loss: 6.6541\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.65406 to 6.63996, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 243s - loss: 6.6050 - val_loss: 6.6400\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.63996 to 6.60451, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.917_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 243s - loss: 6.5797 - val_loss: 6.6045\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.60451\n",
      "177316/177316 - 244s - loss: 6.5541 - val_loss: 6.6425\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.60451\n",
      "177316/177316 - 242s - loss: 6.5299 - val_loss: 6.6855\n",
      "[6.900357414075562, 6.787100696174325, 6.737906932411296, 6.695735833090302, 6.661755012092779, 6.631556141537578, 6.605017030754624, 6.579655930363927, 6.554129551151297, 6.529854615081179]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  2422.526834487915  epochs in 2476.2656564712524 s\n",
      "Last train cost :  6.668306915673287\n",
      "recall :  0.04841186986597278\n",
      "precision :  0.07758346581876029\n",
      "sps :  0.058823529411764705\n",
      "Best  sps :  0.058823529411764705\n",
      "user_coverage :  0.505564387917329\n",
      "item_coverage :  114\n",
      "ndcg :  0.08390476185460839\n",
      "blockbuster_share :  0.45081967213114754\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2422.527_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 100  --min_iter 10 --r_emb 100 --r_emb_opt lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 18:27:50.688075: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 18:27:50.711084: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 18:27:50.711400: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3a21750 executing computations on platform Host. Devices:\n",
      "2019-12-08 18:27:50.711426: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 18:27:58.865701: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7372_7971_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8090' and '__inference___backward_standard_lstm_7372_7971' both implement 'lstm_de970266-ff0e-44bc-aae5-3c26c3036a8c' but their signatures do not match.\n",
      "2019-12-08 18:31:49.505941: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19753' and '__inference_standard_lstm_19410_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21278' both implement 'lstm_929bffde-54a9-4807-a465-d8605a0ef50c' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.85168, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.825_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 234s - loss: 6.9328 - val_loss: 6.8517\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.85168 to 6.76717, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.825_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 240s - loss: 6.8109 - val_loss: 6.7672\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.76717 to 6.76570, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.825_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 241s - loss: 6.7748 - val_loss: 6.7657\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.76570 to 6.73645, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.825_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 242s - loss: 6.7466 - val_loss: 6.7364\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.73645\n",
      "177316/177316 - 237s - loss: 6.7159 - val_loss: 6.7431\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.73645 to 6.73055, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.825_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 243s - loss: 6.6953 - val_loss: 6.7306\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.73055 to 6.70131, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.825_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 243s - loss: 6.6756 - val_loss: 6.7013\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.70131 to 6.68020, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.825_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 245s - loss: 6.6563 - val_loss: 6.6802\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.68020\n",
      "177316/177316 - 239s - loss: 6.6379 - val_loss: 6.7045\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.68020\n",
      "177316/177316 - 237s - loss: 6.6192 - val_loss: 6.7046\n",
      "[6.932848278541241, 6.81093351899436, 6.774789036348899, 6.746568455035963, 6.715921419597139, 6.695346635480159, 6.67562738331148, 6.656339929848705, 6.6378877531729445, 6.61918183662139]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  2402.5848517417908  epochs in 2457.0072586536407 s\n",
      "Last train cost :  6.726544424695229\n",
      "recall :  0.0498946175127992\n",
      "precision :  0.08012718600953932\n",
      "sps :  0.05405405405405406\n",
      "Best  sps :  0.05405405405405406\n",
      "user_coverage :  0.5310015898251192\n",
      "item_coverage :  78\n",
      "ndcg :  0.08647292219359609\n",
      "blockbuster_share :  0.5634920634920635\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2402.585_gc100_e100_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 100  --min_iter 10 --r_emb 100 --r_emb_opt tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 19:16:04.226925: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 19:16:04.251104: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 19:16:04.251424: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x49b5410 executing computations on platform Host. Devices:\n",
      "2019-12-08 19:16:04.251450: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 19:16:11.886578: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_with_fallback_5815_7274' and '__inference___backward_standard_lstm_7392_7991_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8128' both implement 'lstm_186f6af0-d18d-4ced-97cb-fde364df7541' but their signatures do not match.\n",
      "2019-12-08 19:21:41.539239: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_19446' and '__inference_standard_lstm_19446_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21314' both implement 'lstm_e2c8a813-a935-4718-93b7-290ed9c7c522' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.90929, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 334s - loss: 6.9483 - val_loss: 6.9093\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.90929 to 6.86318, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 325s - loss: 6.8983 - val_loss: 6.8632\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.86318 to 6.80928, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 326s - loss: 6.8290 - val_loss: 6.8093\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.80928 to 6.76434, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 329s - loss: 6.7848 - val_loss: 6.7643\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.76434 to 6.72089, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 327s - loss: 6.7221 - val_loss: 6.7209\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.72089 to 6.70573, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 327s - loss: 6.6570 - val_loss: 6.7057\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.70573 to 6.67620, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 329s - loss: 6.6163 - val_loss: 6.6762\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.67620 to 6.59822, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 327s - loss: 6.5794 - val_loss: 6.5982\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.59822\n",
      "177316/177316 - 327s - loss: 6.5409 - val_loss: 6.6057\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss improved from 6.59822 to 6.56253, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.649_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 327s - loss: 6.5026 - val_loss: 6.5625\n",
      "[6.948282116859813, 6.898323431890401, 6.829027530468196, 6.784833767887982, 6.722064285490874, 6.657030629682499, 6.616250094340375, 6.579442675941036, 6.5409266300120095, 6.502640888287516]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  3277.95161151886  epochs in 3334.039526462555 s\n",
      "Last train cost :  6.7078822050860705\n",
      "recall :  0.04909873013970709\n",
      "precision :  0.08092209856915772\n",
      "sps :  0.05087440381558029\n",
      "Best  sps :  0.05087440381558029\n",
      "user_coverage :  0.5246422893481717\n",
      "item_coverage :  128\n",
      "ndcg :  0.0851564145453465\n",
      "blockbuster_share :  0.40471512770137524\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne3277.952_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 100 --min_iter 10 --r_emb 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 20:11:45.189906: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 20:11:45.211070: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 20:11:45.211406: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x50b43d0 executing computations on platform Host. Devices:\n",
      "2019-12-08 20:11:45.211448: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 20:11:53.333098: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7372_7971_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8090' and '__inference___backward_standard_lstm_7372_7971' both implement 'lstm_7223148f-6b2d-4ced-b2a6-191170b3cc44' but their signatures do not match.\n",
      "2019-12-08 20:17:01.971088: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19753' and '__inference_standard_lstm_19410_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21278' both implement 'lstm_38637a0b-d8ce-4db5-8649-95b6a7f71e67' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.81266, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.796_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 313s - loss: 6.9083 - val_loss: 6.8127\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.81266 to 6.76192, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.796_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 313s - loss: 6.7868 - val_loss: 6.7619\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.76192 to 6.71104, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.796_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 313s - loss: 6.7312 - val_loss: 6.7110\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.71104 to 6.66162, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.796_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 312s - loss: 6.6825 - val_loss: 6.6616\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.66162\n",
      "177316/177316 - 313s - loss: 6.6446 - val_loss: 6.6664\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.66162 to 6.65946, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.796_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 313s - loss: 6.6103 - val_loss: 6.6595\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.65946 to 6.61444, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.796_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 313s - loss: 6.5794 - val_loss: 6.6144\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.61444 to 6.57498, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.796_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 315s - loss: 6.5484 - val_loss: 6.5750\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.57498\n",
      "177316/177316 - 312s - loss: 6.5178 - val_loss: 6.6069\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.57498\n",
      "177316/177316 - 312s - loss: 6.4888 - val_loss: 6.6843\n",
      "[6.908305372487587, 6.7867804313782205, 6.731160638769576, 6.682489847421039, 6.6445799570940505, 6.610251301337301, 6.579400194482146, 6.548414636985113, 6.517842042045178, 6.4887742018532375]\n",
      "Opening file (1)\n",
      "RNN with categorical cross entropy 0 batchs,  3129.248851776123  epochs in 3181.8081562519073 s\n",
      "Last train cost :  6.649799862385345\n",
      "recall :  0.04613757759059107\n",
      "precision :  0.07392686804451536\n",
      "sps :  0.05405405405405406\n",
      "Best  sps :  0.05405405405405406\n",
      "user_coverage :  0.48012718600953896\n",
      "item_coverage :  104\n",
      "ndcg :  0.07968357917384924\n",
      "blockbuster_share :  0.4774193548387097\n",
      "-----------------\n",
      "Save model in ks-cooks-1y/models/rnn_cce_ml60_bs32_ne3129.249_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 100 --min_iter 10 --r_emb 300 --r_emb_opt lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 21:04:59.063751: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-08 21:04:59.087076: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1895410000 Hz\n",
      "2019-12-08 21:04:59.087472: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x489ede0 executing computations on platform Host. Devices:\n",
      "2019-12-08 21:04:59.087536: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 177316 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "2019-12-08 21:05:07.259273: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_7372_7971_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_8090' and '__inference___backward_standard_lstm_7372_7971' both implement 'lstm_3e31ddbe-f3b8-4527-9558-996ddf0bc8f4' but their signatures do not match.\n",
      "2019-12-08 21:10:23.609478: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_19753' and '__inference_standard_lstm_19410_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_21278' both implement 'lstm_4e0c3232-89b6-46c5-9167-2bbd277a554e' but their signatures do not match.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.92423, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 320s - loss: 6.9468 - val_loss: 6.9242\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.92423 to 6.83542, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 319s - loss: 6.8919 - val_loss: 6.8354\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.83542 to 6.77275, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 320s - loss: 6.8113 - val_loss: 6.7728\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 6.77275\n",
      "177316/177316 - 319s - loss: 6.7708 - val_loss: 6.7803\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.77275 to 6.77171, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 320s - loss: 6.7390 - val_loss: 6.7717\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.77171 to 6.74518, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 319s - loss: 6.6991 - val_loss: 6.7452\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.74518 to 6.69791, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 320s - loss: 6.6685 - val_loss: 6.6979\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 6.69791\n",
      "177316/177316 - 318s - loss: 6.6388 - val_loss: 6.7110\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.69791 to 6.68109, saving model to ks-cooks-1y/models/rnn_cce_ml60_bs32_ne2.833_gc100_e300_h100_Ug_lr0.1_nt1.hdf5\n",
      "177316/177316 - 316s - loss: 6.6115 - val_loss: 6.6811\n",
      "Epoch 10/10\n"
     ]
    }
   ],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 100 --min_iter 10 --r_emb 300 --r_emb_opt tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull origin remote_PC\n",
    "!git add .\n",
    "!git commit -m 'Comparing three embedding methods with h100'\n",
    "!git push -u origin remote_PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 150 --min_iter 10 --r_emb 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 150 --min_iter 10 --r_emb 300 --r_emb_opt lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -d ks-cooks-1y -b 32 --max_length 60 --r_l 150 --min_iter 10 --r_emb 300 --r_emb_opt tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull origin remote_PC\n",
    "!git add .\n",
    "!git commit -m 'Comparing three embedding methods with h150'\n",
    "!git push -u origin remote_PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-python3-virlenv",
   "language": "python",
   "name": "my-python3-virlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
